{
  "best_global_step": 22500,
  "best_metric": 0.9305,
  "best_model_checkpoint": "distilbert-base-uncased-lora-text-classification/checkpoint-22500",
  "epoch": 9.0,
  "eval_steps": 500,
  "global_step": 22500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.02,
      "grad_norm": 1.3854197263717651,
      "learning_rate": 0.00099804,
      "loss": 0.486,
      "step": 50
    },
    {
      "epoch": 0.04,
      "grad_norm": 2.94626522064209,
      "learning_rate": 0.0009960400000000001,
      "loss": 0.3182,
      "step": 100
    },
    {
      "epoch": 0.06,
      "grad_norm": 6.3020734786987305,
      "learning_rate": 0.00099404,
      "loss": 0.2685,
      "step": 150
    },
    {
      "epoch": 0.08,
      "grad_norm": 4.087368965148926,
      "learning_rate": 0.00099204,
      "loss": 0.2682,
      "step": 200
    },
    {
      "epoch": 0.1,
      "grad_norm": 2.3907697200775146,
      "learning_rate": 0.00099004,
      "loss": 0.3102,
      "step": 250
    },
    {
      "epoch": 0.12,
      "grad_norm": 6.238348007202148,
      "learning_rate": 0.00098808,
      "loss": 0.3244,
      "step": 300
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.5243388414382935,
      "learning_rate": 0.00098608,
      "loss": 0.312,
      "step": 350
    },
    {
      "epoch": 0.16,
      "grad_norm": 2.674229383468628,
      "learning_rate": 0.00098408,
      "loss": 0.3112,
      "step": 400
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.6964319944381714,
      "learning_rate": 0.00098208,
      "loss": 0.3132,
      "step": 450
    },
    {
      "epoch": 0.2,
      "grad_norm": 2.2963807582855225,
      "learning_rate": 0.00098008,
      "loss": 0.2657,
      "step": 500
    },
    {
      "epoch": 0.22,
      "grad_norm": 2.63368558883667,
      "learning_rate": 0.0009780799999999999,
      "loss": 0.2803,
      "step": 550
    },
    {
      "epoch": 0.24,
      "grad_norm": 2.2774057388305664,
      "learning_rate": 0.0009760799999999999,
      "loss": 0.2791,
      "step": 600
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.865176796913147,
      "learning_rate": 0.00097408,
      "loss": 0.2863,
      "step": 650
    },
    {
      "epoch": 0.28,
      "grad_norm": 3.489137649536133,
      "learning_rate": 0.0009720800000000001,
      "loss": 0.293,
      "step": 700
    },
    {
      "epoch": 0.3,
      "grad_norm": 2.693746566772461,
      "learning_rate": 0.0009700800000000001,
      "loss": 0.269,
      "step": 750
    },
    {
      "epoch": 0.32,
      "grad_norm": 2.6282525062561035,
      "learning_rate": 0.0009680800000000001,
      "loss": 0.3114,
      "step": 800
    },
    {
      "epoch": 0.34,
      "grad_norm": 2.716804265975952,
      "learning_rate": 0.00096608,
      "loss": 0.3247,
      "step": 850
    },
    {
      "epoch": 0.36,
      "grad_norm": 4.102995872497559,
      "learning_rate": 0.0009640800000000001,
      "loss": 0.2519,
      "step": 900
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.3884878158569336,
      "learning_rate": 0.00096208,
      "loss": 0.2543,
      "step": 950
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.3145837783813477,
      "learning_rate": 0.0009600800000000001,
      "loss": 0.3045,
      "step": 1000
    },
    {
      "epoch": 0.42,
      "grad_norm": 2.153337001800537,
      "learning_rate": 0.00095808,
      "loss": 0.2641,
      "step": 1050
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.134870171546936,
      "learning_rate": 0.0009560800000000001,
      "loss": 0.2727,
      "step": 1100
    },
    {
      "epoch": 0.46,
      "grad_norm": 2.7783360481262207,
      "learning_rate": 0.00095408,
      "loss": 0.3019,
      "step": 1150
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.8630924224853516,
      "learning_rate": 0.00095208,
      "loss": 0.2566,
      "step": 1200
    },
    {
      "epoch": 0.5,
      "grad_norm": 2.374300718307495,
      "learning_rate": 0.0009500800000000001,
      "loss": 0.2792,
      "step": 1250
    },
    {
      "epoch": 0.52,
      "grad_norm": 3.6234850883483887,
      "learning_rate": 0.00094808,
      "loss": 0.2452,
      "step": 1300
    },
    {
      "epoch": 0.54,
      "grad_norm": 2.173086166381836,
      "learning_rate": 0.0009460800000000001,
      "loss": 0.2508,
      "step": 1350
    },
    {
      "epoch": 0.56,
      "grad_norm": 2.1238484382629395,
      "learning_rate": 0.00094408,
      "loss": 0.277,
      "step": 1400
    },
    {
      "epoch": 0.58,
      "grad_norm": 2.1102981567382812,
      "learning_rate": 0.0009420800000000001,
      "loss": 0.2544,
      "step": 1450
    },
    {
      "epoch": 0.6,
      "grad_norm": 4.3198041915893555,
      "learning_rate": 0.00094008,
      "loss": 0.2998,
      "step": 1500
    },
    {
      "epoch": 0.62,
      "grad_norm": 3.0818045139312744,
      "learning_rate": 0.0009380800000000001,
      "loss": 0.261,
      "step": 1550
    },
    {
      "epoch": 0.64,
      "grad_norm": 2.054262638092041,
      "learning_rate": 0.00093608,
      "loss": 0.2609,
      "step": 1600
    },
    {
      "epoch": 0.66,
      "grad_norm": 1.997979760169983,
      "learning_rate": 0.00093408,
      "loss": 0.2543,
      "step": 1650
    },
    {
      "epoch": 0.68,
      "grad_norm": 1.6890510320663452,
      "learning_rate": 0.0009320800000000001,
      "loss": 0.2675,
      "step": 1700
    },
    {
      "epoch": 0.7,
      "grad_norm": 3.3484084606170654,
      "learning_rate": 0.00093008,
      "loss": 0.2876,
      "step": 1750
    },
    {
      "epoch": 0.72,
      "grad_norm": 1.462646245956421,
      "learning_rate": 0.0009280800000000001,
      "loss": 0.2311,
      "step": 1800
    },
    {
      "epoch": 0.74,
      "grad_norm": 3.901885509490967,
      "learning_rate": 0.00092608,
      "loss": 0.2634,
      "step": 1850
    },
    {
      "epoch": 0.76,
      "grad_norm": 1.3349018096923828,
      "learning_rate": 0.0009240800000000001,
      "loss": 0.2904,
      "step": 1900
    },
    {
      "epoch": 0.78,
      "grad_norm": 0.5464964509010315,
      "learning_rate": 0.00092208,
      "loss": 0.2161,
      "step": 1950
    },
    {
      "epoch": 0.8,
      "grad_norm": 2.0331177711486816,
      "learning_rate": 0.00092008,
      "loss": 0.2778,
      "step": 2000
    },
    {
      "epoch": 0.82,
      "grad_norm": 4.103893280029297,
      "learning_rate": 0.00091808,
      "loss": 0.2208,
      "step": 2050
    },
    {
      "epoch": 0.84,
      "grad_norm": 5.530495643615723,
      "learning_rate": 0.00091608,
      "loss": 0.2589,
      "step": 2100
    },
    {
      "epoch": 0.86,
      "grad_norm": 1.890191912651062,
      "learning_rate": 0.0009140800000000001,
      "loss": 0.2697,
      "step": 2150
    },
    {
      "epoch": 0.88,
      "grad_norm": 2.338064670562744,
      "learning_rate": 0.00091208,
      "loss": 0.2724,
      "step": 2200
    },
    {
      "epoch": 0.9,
      "grad_norm": 1.9559682607650757,
      "learning_rate": 0.0009100800000000001,
      "loss": 0.2788,
      "step": 2250
    },
    {
      "epoch": 0.92,
      "grad_norm": 4.218642234802246,
      "learning_rate": 0.0009081200000000001,
      "loss": 0.2357,
      "step": 2300
    },
    {
      "epoch": 0.94,
      "grad_norm": 4.175474643707275,
      "learning_rate": 0.0009061200000000001,
      "loss": 0.2343,
      "step": 2350
    },
    {
      "epoch": 0.96,
      "grad_norm": 2.282357931137085,
      "learning_rate": 0.00090412,
      "loss": 0.2784,
      "step": 2400
    },
    {
      "epoch": 0.98,
      "grad_norm": 2.9681525230407715,
      "learning_rate": 0.0009021200000000001,
      "loss": 0.2448,
      "step": 2450
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.9159194231033325,
      "learning_rate": 0.00090012,
      "loss": 0.2937,
      "step": 2500
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9,
      "eval_f1": 0.8965659908978071,
      "eval_loss": 0.24235068261623383,
      "eval_runtime": 76.8457,
      "eval_samples_per_second": 130.131,
      "eval_steps_per_second": 4.073,
      "step": 2500
    },
    {
      "epoch": 1.02,
      "grad_norm": 2.0054538249969482,
      "learning_rate": 0.0008981200000000001,
      "loss": 0.2336,
      "step": 2550
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.444845587015152,
      "learning_rate": 0.00089612,
      "loss": 0.232,
      "step": 2600
    },
    {
      "epoch": 1.06,
      "grad_norm": 2.9746291637420654,
      "learning_rate": 0.0008941200000000001,
      "loss": 0.2069,
      "step": 2650
    },
    {
      "epoch": 1.08,
      "grad_norm": 5.330363750457764,
      "learning_rate": 0.00089212,
      "loss": 0.2154,
      "step": 2700
    },
    {
      "epoch": 1.1,
      "grad_norm": 4.437604904174805,
      "learning_rate": 0.00089012,
      "loss": 0.2584,
      "step": 2750
    },
    {
      "epoch": 1.12,
      "grad_norm": 3.3562018871307373,
      "learning_rate": 0.0008881200000000001,
      "loss": 0.2494,
      "step": 2800
    },
    {
      "epoch": 1.1400000000000001,
      "grad_norm": 2.589137315750122,
      "learning_rate": 0.00088612,
      "loss": 0.2099,
      "step": 2850
    },
    {
      "epoch": 1.16,
      "grad_norm": 1.3548463582992554,
      "learning_rate": 0.0008841200000000001,
      "loss": 0.2114,
      "step": 2900
    },
    {
      "epoch": 1.18,
      "grad_norm": 5.1071977615356445,
      "learning_rate": 0.00088212,
      "loss": 0.2143,
      "step": 2950
    },
    {
      "epoch": 1.2,
      "grad_norm": 1.0127367973327637,
      "learning_rate": 0.0008801200000000001,
      "loss": 0.2377,
      "step": 3000
    },
    {
      "epoch": 1.22,
      "grad_norm": 1.6598743200302124,
      "learning_rate": 0.00087812,
      "loss": 0.2512,
      "step": 3050
    },
    {
      "epoch": 1.24,
      "grad_norm": 4.329615116119385,
      "learning_rate": 0.00087612,
      "loss": 0.2149,
      "step": 3100
    },
    {
      "epoch": 1.26,
      "grad_norm": 4.401605606079102,
      "learning_rate": 0.00087412,
      "loss": 0.2258,
      "step": 3150
    },
    {
      "epoch": 1.28,
      "grad_norm": 3.0096757411956787,
      "learning_rate": 0.00087212,
      "loss": 0.253,
      "step": 3200
    },
    {
      "epoch": 1.3,
      "grad_norm": 3.4865596294403076,
      "learning_rate": 0.00087012,
      "loss": 0.2193,
      "step": 3250
    },
    {
      "epoch": 1.32,
      "grad_norm": 4.444305896759033,
      "learning_rate": 0.00086812,
      "loss": 0.241,
      "step": 3300
    },
    {
      "epoch": 1.34,
      "grad_norm": 1.8327422142028809,
      "learning_rate": 0.0008661200000000001,
      "loss": 0.2689,
      "step": 3350
    },
    {
      "epoch": 1.3599999999999999,
      "grad_norm": 2.3998074531555176,
      "learning_rate": 0.00086412,
      "loss": 0.2801,
      "step": 3400
    },
    {
      "epoch": 1.38,
      "grad_norm": 3.413750171661377,
      "learning_rate": 0.00086212,
      "loss": 0.2501,
      "step": 3450
    },
    {
      "epoch": 1.4,
      "grad_norm": 1.9790215492248535,
      "learning_rate": 0.00086012,
      "loss": 0.2269,
      "step": 3500
    },
    {
      "epoch": 1.42,
      "grad_norm": 0.6449129581451416,
      "learning_rate": 0.00085812,
      "loss": 0.2152,
      "step": 3550
    },
    {
      "epoch": 1.44,
      "grad_norm": 3.3009400367736816,
      "learning_rate": 0.00085612,
      "loss": 0.1891,
      "step": 3600
    },
    {
      "epoch": 1.46,
      "grad_norm": 2.734077215194702,
      "learning_rate": 0.00085412,
      "loss": 0.2138,
      "step": 3650
    },
    {
      "epoch": 1.48,
      "grad_norm": 1.2667210102081299,
      "learning_rate": 0.00085212,
      "loss": 0.2613,
      "step": 3700
    },
    {
      "epoch": 1.5,
      "grad_norm": 3.514425754547119,
      "learning_rate": 0.00085012,
      "loss": 0.2365,
      "step": 3750
    },
    {
      "epoch": 1.52,
      "grad_norm": 2.721975088119507,
      "learning_rate": 0.00084812,
      "loss": 0.2682,
      "step": 3800
    },
    {
      "epoch": 1.54,
      "grad_norm": 4.021571636199951,
      "learning_rate": 0.00084612,
      "loss": 0.2194,
      "step": 3850
    },
    {
      "epoch": 1.56,
      "grad_norm": 1.736588478088379,
      "learning_rate": 0.00084412,
      "loss": 0.2499,
      "step": 3900
    },
    {
      "epoch": 1.58,
      "grad_norm": 3.62427020072937,
      "learning_rate": 0.00084212,
      "loss": 0.236,
      "step": 3950
    },
    {
      "epoch": 1.6,
      "grad_norm": 1.4243645668029785,
      "learning_rate": 0.00084012,
      "loss": 0.2199,
      "step": 4000
    },
    {
      "epoch": 1.62,
      "grad_norm": 2.2147326469421387,
      "learning_rate": 0.00083812,
      "loss": 0.2261,
      "step": 4050
    },
    {
      "epoch": 1.6400000000000001,
      "grad_norm": 0.36419230699539185,
      "learning_rate": 0.00083612,
      "loss": 0.2405,
      "step": 4100
    },
    {
      "epoch": 1.6600000000000001,
      "grad_norm": 6.1515631675720215,
      "learning_rate": 0.00083412,
      "loss": 0.2007,
      "step": 4150
    },
    {
      "epoch": 1.6800000000000002,
      "grad_norm": 1.8670978546142578,
      "learning_rate": 0.00083212,
      "loss": 0.2717,
      "step": 4200
    },
    {
      "epoch": 1.7,
      "grad_norm": 6.171207427978516,
      "learning_rate": 0.00083012,
      "loss": 0.2526,
      "step": 4250
    },
    {
      "epoch": 1.72,
      "grad_norm": 3.5926036834716797,
      "learning_rate": 0.00082812,
      "loss": 0.2426,
      "step": 4300
    },
    {
      "epoch": 1.74,
      "grad_norm": 4.069119930267334,
      "learning_rate": 0.00082612,
      "loss": 0.2477,
      "step": 4350
    },
    {
      "epoch": 1.76,
      "grad_norm": 5.010245323181152,
      "learning_rate": 0.00082416,
      "loss": 0.2351,
      "step": 4400
    },
    {
      "epoch": 1.78,
      "grad_norm": 4.425065517425537,
      "learning_rate": 0.0008221600000000001,
      "loss": 0.2257,
      "step": 4450
    },
    {
      "epoch": 1.8,
      "grad_norm": 1.2708529233932495,
      "learning_rate": 0.00082016,
      "loss": 0.2405,
      "step": 4500
    },
    {
      "epoch": 1.8199999999999998,
      "grad_norm": 2.1401760578155518,
      "learning_rate": 0.0008181600000000001,
      "loss": 0.2195,
      "step": 4550
    },
    {
      "epoch": 1.8399999999999999,
      "grad_norm": 2.8035848140716553,
      "learning_rate": 0.00081616,
      "loss": 0.2429,
      "step": 4600
    },
    {
      "epoch": 1.8599999999999999,
      "grad_norm": 3.8328769207000732,
      "learning_rate": 0.00081416,
      "loss": 0.2673,
      "step": 4650
    },
    {
      "epoch": 1.88,
      "grad_norm": 2.182041645050049,
      "learning_rate": 0.00081216,
      "loss": 0.2353,
      "step": 4700
    },
    {
      "epoch": 1.9,
      "grad_norm": 2.9974446296691895,
      "learning_rate": 0.00081016,
      "loss": 0.2338,
      "step": 4750
    },
    {
      "epoch": 1.92,
      "grad_norm": 1.4556578397750854,
      "learning_rate": 0.00080816,
      "loss": 0.2427,
      "step": 4800
    },
    {
      "epoch": 1.94,
      "grad_norm": 2.208995819091797,
      "learning_rate": 0.00080616,
      "loss": 0.2448,
      "step": 4850
    },
    {
      "epoch": 1.96,
      "grad_norm": 8.41718578338623,
      "learning_rate": 0.00080416,
      "loss": 0.232,
      "step": 4900
    },
    {
      "epoch": 1.98,
      "grad_norm": 2.4932966232299805,
      "learning_rate": 0.00080216,
      "loss": 0.2155,
      "step": 4950
    },
    {
      "epoch": 2.0,
      "grad_norm": 2.757678270339966,
      "learning_rate": 0.00080016,
      "loss": 0.246,
      "step": 5000
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.9154,
      "eval_f1": 0.9164856860809476,
      "eval_loss": 0.22498388588428497,
      "eval_runtime": 76.8825,
      "eval_samples_per_second": 130.069,
      "eval_steps_per_second": 4.071,
      "step": 5000
    },
    {
      "epoch": 2.02,
      "grad_norm": 2.431007146835327,
      "learning_rate": 0.0007982,
      "loss": 0.2116,
      "step": 5050
    },
    {
      "epoch": 2.04,
      "grad_norm": 2.8245561122894287,
      "learning_rate": 0.0007962000000000001,
      "loss": 0.1852,
      "step": 5100
    },
    {
      "epoch": 2.06,
      "grad_norm": 3.4817721843719482,
      "learning_rate": 0.0007942,
      "loss": 0.2026,
      "step": 5150
    },
    {
      "epoch": 2.08,
      "grad_norm": 2.716029167175293,
      "learning_rate": 0.0007922000000000001,
      "loss": 0.2032,
      "step": 5200
    },
    {
      "epoch": 2.1,
      "grad_norm": 0.6256205439567566,
      "learning_rate": 0.0007902,
      "loss": 0.2684,
      "step": 5250
    },
    {
      "epoch": 2.12,
      "grad_norm": 1.0947551727294922,
      "learning_rate": 0.0007882000000000001,
      "loss": 0.2313,
      "step": 5300
    },
    {
      "epoch": 2.14,
      "grad_norm": 2.6031734943389893,
      "learning_rate": 0.0007862,
      "loss": 0.2144,
      "step": 5350
    },
    {
      "epoch": 2.16,
      "grad_norm": 4.029591083526611,
      "learning_rate": 0.0007842,
      "loss": 0.2054,
      "step": 5400
    },
    {
      "epoch": 2.18,
      "grad_norm": 2.507194757461548,
      "learning_rate": 0.0007822,
      "loss": 0.2348,
      "step": 5450
    },
    {
      "epoch": 2.2,
      "grad_norm": 2.312013626098633,
      "learning_rate": 0.0007802,
      "loss": 0.2203,
      "step": 5500
    },
    {
      "epoch": 2.22,
      "grad_norm": 3.288628101348877,
      "learning_rate": 0.0007782,
      "loss": 0.2429,
      "step": 5550
    },
    {
      "epoch": 2.24,
      "grad_norm": 2.8967180252075195,
      "learning_rate": 0.0007762,
      "loss": 0.2128,
      "step": 5600
    },
    {
      "epoch": 2.26,
      "grad_norm": 3.1245131492614746,
      "learning_rate": 0.0007742000000000001,
      "loss": 0.2108,
      "step": 5650
    },
    {
      "epoch": 2.2800000000000002,
      "grad_norm": 2.58891224861145,
      "learning_rate": 0.0007722400000000001,
      "loss": 0.1902,
      "step": 5700
    },
    {
      "epoch": 2.3,
      "grad_norm": 4.399017333984375,
      "learning_rate": 0.00077024,
      "loss": 0.2345,
      "step": 5750
    },
    {
      "epoch": 2.32,
      "grad_norm": 4.795790672302246,
      "learning_rate": 0.00076824,
      "loss": 0.2294,
      "step": 5800
    },
    {
      "epoch": 2.34,
      "grad_norm": 2.7842888832092285,
      "learning_rate": 0.0007662400000000001,
      "loss": 0.1999,
      "step": 5850
    },
    {
      "epoch": 2.36,
      "grad_norm": 4.647283554077148,
      "learning_rate": 0.00076424,
      "loss": 0.2202,
      "step": 5900
    },
    {
      "epoch": 2.38,
      "grad_norm": 2.658693313598633,
      "learning_rate": 0.0007622400000000001,
      "loss": 0.2382,
      "step": 5950
    },
    {
      "epoch": 2.4,
      "grad_norm": 3.081502676010132,
      "learning_rate": 0.00076024,
      "loss": 0.2033,
      "step": 6000
    },
    {
      "epoch": 2.42,
      "grad_norm": 4.801247596740723,
      "learning_rate": 0.0007582400000000001,
      "loss": 0.209,
      "step": 6050
    },
    {
      "epoch": 2.44,
      "grad_norm": 2.551894187927246,
      "learning_rate": 0.00075624,
      "loss": 0.2118,
      "step": 6100
    },
    {
      "epoch": 2.46,
      "grad_norm": 2.6454875469207764,
      "learning_rate": 0.00075424,
      "loss": 0.2004,
      "step": 6150
    },
    {
      "epoch": 2.48,
      "grad_norm": 2.423448324203491,
      "learning_rate": 0.00075224,
      "loss": 0.2216,
      "step": 6200
    },
    {
      "epoch": 2.5,
      "grad_norm": 2.1353814601898193,
      "learning_rate": 0.00075024,
      "loss": 0.1948,
      "step": 6250
    },
    {
      "epoch": 2.52,
      "grad_norm": 4.441800117492676,
      "learning_rate": 0.0007482400000000001,
      "loss": 0.1915,
      "step": 6300
    },
    {
      "epoch": 2.54,
      "grad_norm": 4.5858893394470215,
      "learning_rate": 0.00074624,
      "loss": 0.2144,
      "step": 6350
    },
    {
      "epoch": 2.56,
      "grad_norm": 2.1634676456451416,
      "learning_rate": 0.0007442400000000001,
      "loss": 0.2368,
      "step": 6400
    },
    {
      "epoch": 2.58,
      "grad_norm": 2.5129783153533936,
      "learning_rate": 0.00074224,
      "loss": 0.2427,
      "step": 6450
    },
    {
      "epoch": 2.6,
      "grad_norm": 1.1953703165054321,
      "learning_rate": 0.00074024,
      "loss": 0.2073,
      "step": 6500
    },
    {
      "epoch": 2.62,
      "grad_norm": 3.0943214893341064,
      "learning_rate": 0.00073824,
      "loss": 0.2066,
      "step": 6550
    },
    {
      "epoch": 2.64,
      "grad_norm": 5.031052589416504,
      "learning_rate": 0.00073624,
      "loss": 0.2226,
      "step": 6600
    },
    {
      "epoch": 2.66,
      "grad_norm": 2.278292417526245,
      "learning_rate": 0.00073424,
      "loss": 0.2265,
      "step": 6650
    },
    {
      "epoch": 2.68,
      "grad_norm": 0.6814972758293152,
      "learning_rate": 0.00073224,
      "loss": 0.1961,
      "step": 6700
    },
    {
      "epoch": 2.7,
      "grad_norm": 4.18797492980957,
      "learning_rate": 0.0007302400000000001,
      "loss": 0.2385,
      "step": 6750
    },
    {
      "epoch": 2.7199999999999998,
      "grad_norm": 4.624583721160889,
      "learning_rate": 0.00072824,
      "loss": 0.2121,
      "step": 6800
    },
    {
      "epoch": 2.74,
      "grad_norm": 3.1756091117858887,
      "learning_rate": 0.00072624,
      "loss": 0.2672,
      "step": 6850
    },
    {
      "epoch": 2.76,
      "grad_norm": 0.627456545829773,
      "learning_rate": 0.00072424,
      "loss": 0.2057,
      "step": 6900
    },
    {
      "epoch": 2.7800000000000002,
      "grad_norm": 3.1997973918914795,
      "learning_rate": 0.00072224,
      "loss": 0.2171,
      "step": 6950
    },
    {
      "epoch": 2.8,
      "grad_norm": 1.055001139640808,
      "learning_rate": 0.00072024,
      "loss": 0.1789,
      "step": 7000
    },
    {
      "epoch": 2.82,
      "grad_norm": 1.2783194780349731,
      "learning_rate": 0.00071824,
      "loss": 0.2205,
      "step": 7050
    },
    {
      "epoch": 2.84,
      "grad_norm": 2.2208709716796875,
      "learning_rate": 0.00071624,
      "loss": 0.2385,
      "step": 7100
    },
    {
      "epoch": 2.86,
      "grad_norm": 3.3459198474884033,
      "learning_rate": 0.00071424,
      "loss": 0.2162,
      "step": 7150
    },
    {
      "epoch": 2.88,
      "grad_norm": 4.722457408905029,
      "learning_rate": 0.00071224,
      "loss": 0.1963,
      "step": 7200
    },
    {
      "epoch": 2.9,
      "grad_norm": 3.86205792427063,
      "learning_rate": 0.00071024,
      "loss": 0.2117,
      "step": 7250
    },
    {
      "epoch": 2.92,
      "grad_norm": 2.312488317489624,
      "learning_rate": 0.00070824,
      "loss": 0.1974,
      "step": 7300
    },
    {
      "epoch": 2.94,
      "grad_norm": 1.6705288887023926,
      "learning_rate": 0.00070624,
      "loss": 0.2119,
      "step": 7350
    },
    {
      "epoch": 2.96,
      "grad_norm": 1.3015104532241821,
      "learning_rate": 0.00070424,
      "loss": 0.2322,
      "step": 7400
    },
    {
      "epoch": 2.98,
      "grad_norm": 3.7262110710144043,
      "learning_rate": 0.00070224,
      "loss": 0.203,
      "step": 7450
    },
    {
      "epoch": 3.0,
      "grad_norm": 2.45879864692688,
      "learning_rate": 0.00070024,
      "loss": 0.2212,
      "step": 7500
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.9131,
      "eval_f1": 0.9157374187918162,
      "eval_loss": 0.22461508214473724,
      "eval_runtime": 76.9046,
      "eval_samples_per_second": 130.031,
      "eval_steps_per_second": 4.07,
      "step": 7500
    },
    {
      "epoch": 3.02,
      "grad_norm": 1.770682454109192,
      "learning_rate": 0.00069824,
      "loss": 0.1906,
      "step": 7550
    },
    {
      "epoch": 3.04,
      "grad_norm": 4.963088512420654,
      "learning_rate": 0.00069624,
      "loss": 0.1932,
      "step": 7600
    },
    {
      "epoch": 3.06,
      "grad_norm": 2.4777302742004395,
      "learning_rate": 0.0006942399999999999,
      "loss": 0.226,
      "step": 7650
    },
    {
      "epoch": 3.08,
      "grad_norm": 1.6529492139816284,
      "learning_rate": 0.00069224,
      "loss": 0.1567,
      "step": 7700
    },
    {
      "epoch": 3.1,
      "grad_norm": 4.421798229217529,
      "learning_rate": 0.00069024,
      "loss": 0.1975,
      "step": 7750
    },
    {
      "epoch": 3.12,
      "grad_norm": 4.04240608215332,
      "learning_rate": 0.00068824,
      "loss": 0.222,
      "step": 7800
    },
    {
      "epoch": 3.14,
      "grad_norm": 1.3719029426574707,
      "learning_rate": 0.00068624,
      "loss": 0.1942,
      "step": 7850
    },
    {
      "epoch": 3.16,
      "grad_norm": 2.4535112380981445,
      "learning_rate": 0.00068424,
      "loss": 0.186,
      "step": 7900
    },
    {
      "epoch": 3.18,
      "grad_norm": 1.091131567955017,
      "learning_rate": 0.00068224,
      "loss": 0.2362,
      "step": 7950
    },
    {
      "epoch": 3.2,
      "grad_norm": 3.680863618850708,
      "learning_rate": 0.0006802399999999999,
      "loss": 0.1523,
      "step": 8000
    },
    {
      "epoch": 3.22,
      "grad_norm": 3.229032039642334,
      "learning_rate": 0.00067824,
      "loss": 0.2076,
      "step": 8050
    },
    {
      "epoch": 3.24,
      "grad_norm": 0.5643740892410278,
      "learning_rate": 0.0006762399999999999,
      "loss": 0.2145,
      "step": 8100
    },
    {
      "epoch": 3.26,
      "grad_norm": 3.869673252105713,
      "learning_rate": 0.00067424,
      "loss": 0.1908,
      "step": 8150
    },
    {
      "epoch": 3.2800000000000002,
      "grad_norm": 6.0895867347717285,
      "learning_rate": 0.00067224,
      "loss": 0.1664,
      "step": 8200
    },
    {
      "epoch": 3.3,
      "grad_norm": 0.6192933917045593,
      "learning_rate": 0.00067024,
      "loss": 0.1876,
      "step": 8250
    },
    {
      "epoch": 3.32,
      "grad_norm": 0.7039663195610046,
      "learning_rate": 0.00066824,
      "loss": 0.1824,
      "step": 8300
    },
    {
      "epoch": 3.34,
      "grad_norm": 3.174160957336426,
      "learning_rate": 0.00066624,
      "loss": 0.1842,
      "step": 8350
    },
    {
      "epoch": 3.36,
      "grad_norm": 3.487191677093506,
      "learning_rate": 0.0006642400000000001,
      "loss": 0.1877,
      "step": 8400
    },
    {
      "epoch": 3.38,
      "grad_norm": 0.6694214940071106,
      "learning_rate": 0.00066224,
      "loss": 0.2104,
      "step": 8450
    },
    {
      "epoch": 3.4,
      "grad_norm": 2.868168592453003,
      "learning_rate": 0.0006602400000000001,
      "loss": 0.1962,
      "step": 8500
    },
    {
      "epoch": 3.42,
      "grad_norm": 0.3301580250263214,
      "learning_rate": 0.00065824,
      "loss": 0.2111,
      "step": 8550
    },
    {
      "epoch": 3.44,
      "grad_norm": 3.63596248626709,
      "learning_rate": 0.0006562400000000001,
      "loss": 0.1756,
      "step": 8600
    },
    {
      "epoch": 3.46,
      "grad_norm": 5.335658073425293,
      "learning_rate": 0.00065424,
      "loss": 0.188,
      "step": 8650
    },
    {
      "epoch": 3.48,
      "grad_norm": 1.2176450490951538,
      "learning_rate": 0.00065224,
      "loss": 0.2431,
      "step": 8700
    },
    {
      "epoch": 3.5,
      "grad_norm": 7.629979133605957,
      "learning_rate": 0.0006502400000000001,
      "loss": 0.1897,
      "step": 8750
    },
    {
      "epoch": 3.52,
      "grad_norm": 1.8231505155563354,
      "learning_rate": 0.00064824,
      "loss": 0.2086,
      "step": 8800
    },
    {
      "epoch": 3.54,
      "grad_norm": 0.21585552394390106,
      "learning_rate": 0.0006462400000000001,
      "loss": 0.1887,
      "step": 8850
    },
    {
      "epoch": 3.56,
      "grad_norm": 1.5101351737976074,
      "learning_rate": 0.00064424,
      "loss": 0.2127,
      "step": 8900
    },
    {
      "epoch": 3.58,
      "grad_norm": 1.9264966249465942,
      "learning_rate": 0.0006422400000000001,
      "loss": 0.2088,
      "step": 8950
    },
    {
      "epoch": 3.6,
      "grad_norm": 5.313746929168701,
      "learning_rate": 0.00064024,
      "loss": 0.1897,
      "step": 9000
    },
    {
      "epoch": 3.62,
      "grad_norm": 9.160661697387695,
      "learning_rate": 0.0006382400000000001,
      "loss": 0.1692,
      "step": 9050
    },
    {
      "epoch": 3.64,
      "grad_norm": 5.8221025466918945,
      "learning_rate": 0.00063624,
      "loss": 0.2382,
      "step": 9100
    },
    {
      "epoch": 3.66,
      "grad_norm": 4.465401649475098,
      "learning_rate": 0.00063424,
      "loss": 0.1668,
      "step": 9150
    },
    {
      "epoch": 3.68,
      "grad_norm": 2.555673360824585,
      "learning_rate": 0.0006322400000000001,
      "loss": 0.219,
      "step": 9200
    },
    {
      "epoch": 3.7,
      "grad_norm": 5.49271821975708,
      "learning_rate": 0.00063024,
      "loss": 0.2075,
      "step": 9250
    },
    {
      "epoch": 3.7199999999999998,
      "grad_norm": 2.892988681793213,
      "learning_rate": 0.0006282400000000001,
      "loss": 0.2516,
      "step": 9300
    },
    {
      "epoch": 3.74,
      "grad_norm": 3.771959066390991,
      "learning_rate": 0.00062624,
      "loss": 0.216,
      "step": 9350
    },
    {
      "epoch": 3.76,
      "grad_norm": 1.3954170942306519,
      "learning_rate": 0.0006242400000000001,
      "loss": 0.179,
      "step": 9400
    },
    {
      "epoch": 3.7800000000000002,
      "grad_norm": 1.864361047744751,
      "learning_rate": 0.00062224,
      "loss": 0.2318,
      "step": 9450
    },
    {
      "epoch": 3.8,
      "grad_norm": 3.38432240486145,
      "learning_rate": 0.00062024,
      "loss": 0.2245,
      "step": 9500
    },
    {
      "epoch": 3.82,
      "grad_norm": 1.907486081123352,
      "learning_rate": 0.00061824,
      "loss": 0.2048,
      "step": 9550
    },
    {
      "epoch": 3.84,
      "grad_norm": 5.164906978607178,
      "learning_rate": 0.00061624,
      "loss": 0.1681,
      "step": 9600
    },
    {
      "epoch": 3.86,
      "grad_norm": 2.605729341506958,
      "learning_rate": 0.0006142400000000001,
      "loss": 0.2129,
      "step": 9650
    },
    {
      "epoch": 3.88,
      "grad_norm": 5.888490200042725,
      "learning_rate": 0.00061224,
      "loss": 0.2038,
      "step": 9700
    },
    {
      "epoch": 3.9,
      "grad_norm": 4.247627258300781,
      "learning_rate": 0.0006102400000000001,
      "loss": 0.2178,
      "step": 9750
    },
    {
      "epoch": 3.92,
      "grad_norm": 0.9219246506690979,
      "learning_rate": 0.0006082800000000001,
      "loss": 0.1604,
      "step": 9800
    },
    {
      "epoch": 3.94,
      "grad_norm": 2.5441009998321533,
      "learning_rate": 0.0006062800000000001,
      "loss": 0.2222,
      "step": 9850
    },
    {
      "epoch": 3.96,
      "grad_norm": 4.29241943359375,
      "learning_rate": 0.00060428,
      "loss": 0.2006,
      "step": 9900
    },
    {
      "epoch": 3.98,
      "grad_norm": 1.4981837272644043,
      "learning_rate": 0.0006022800000000001,
      "loss": 0.2069,
      "step": 9950
    },
    {
      "epoch": 4.0,
      "grad_norm": 2.408496379852295,
      "learning_rate": 0.00060028,
      "loss": 0.2313,
      "step": 10000
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.9248,
      "eval_f1": 0.9246794871794872,
      "eval_loss": 0.2109275460243225,
      "eval_runtime": 76.8967,
      "eval_samples_per_second": 130.045,
      "eval_steps_per_second": 4.07,
      "step": 10000
    },
    {
      "epoch": 4.02,
      "grad_norm": 1.2701345682144165,
      "learning_rate": 0.0005982800000000001,
      "loss": 0.1793,
      "step": 10050
    },
    {
      "epoch": 4.04,
      "grad_norm": 1.219763994216919,
      "learning_rate": 0.00059628,
      "loss": 0.1662,
      "step": 10100
    },
    {
      "epoch": 4.06,
      "grad_norm": 2.755136728286743,
      "learning_rate": 0.0005942800000000001,
      "loss": 0.1659,
      "step": 10150
    },
    {
      "epoch": 4.08,
      "grad_norm": 5.758647441864014,
      "learning_rate": 0.00059228,
      "loss": 0.2071,
      "step": 10200
    },
    {
      "epoch": 4.1,
      "grad_norm": 3.148104667663574,
      "learning_rate": 0.00059028,
      "loss": 0.1922,
      "step": 10250
    },
    {
      "epoch": 4.12,
      "grad_norm": 1.1755634546279907,
      "learning_rate": 0.00058828,
      "loss": 0.1741,
      "step": 10300
    },
    {
      "epoch": 4.14,
      "grad_norm": 2.0489654541015625,
      "learning_rate": 0.00058628,
      "loss": 0.1925,
      "step": 10350
    },
    {
      "epoch": 4.16,
      "grad_norm": 2.307029962539673,
      "learning_rate": 0.0005842800000000001,
      "loss": 0.1748,
      "step": 10400
    },
    {
      "epoch": 4.18,
      "grad_norm": 2.9212560653686523,
      "learning_rate": 0.00058228,
      "loss": 0.1824,
      "step": 10450
    },
    {
      "epoch": 4.2,
      "grad_norm": 2.211494207382202,
      "learning_rate": 0.0005802800000000001,
      "loss": 0.1709,
      "step": 10500
    },
    {
      "epoch": 4.22,
      "grad_norm": 4.558926582336426,
      "learning_rate": 0.00057828,
      "loss": 0.151,
      "step": 10550
    },
    {
      "epoch": 4.24,
      "grad_norm": 3.3468148708343506,
      "learning_rate": 0.00057628,
      "loss": 0.1891,
      "step": 10600
    },
    {
      "epoch": 4.26,
      "grad_norm": 6.458919525146484,
      "learning_rate": 0.00057428,
      "loss": 0.1825,
      "step": 10650
    },
    {
      "epoch": 4.28,
      "grad_norm": 2.3920443058013916,
      "learning_rate": 0.00057228,
      "loss": 0.1891,
      "step": 10700
    },
    {
      "epoch": 4.3,
      "grad_norm": 1.4420117139816284,
      "learning_rate": 0.00057028,
      "loss": 0.1575,
      "step": 10750
    },
    {
      "epoch": 4.32,
      "grad_norm": 2.0574872493743896,
      "learning_rate": 0.00056828,
      "loss": 0.192,
      "step": 10800
    },
    {
      "epoch": 4.34,
      "grad_norm": 4.96439790725708,
      "learning_rate": 0.0005662800000000001,
      "loss": 0.1854,
      "step": 10850
    },
    {
      "epoch": 4.36,
      "grad_norm": 5.166299343109131,
      "learning_rate": 0.00056428,
      "loss": 0.1835,
      "step": 10900
    },
    {
      "epoch": 4.38,
      "grad_norm": 2.1114954948425293,
      "learning_rate": 0.00056228,
      "loss": 0.1846,
      "step": 10950
    },
    {
      "epoch": 4.4,
      "grad_norm": 8.969134330749512,
      "learning_rate": 0.00056028,
      "loss": 0.193,
      "step": 11000
    },
    {
      "epoch": 4.42,
      "grad_norm": 2.690784454345703,
      "learning_rate": 0.00055828,
      "loss": 0.1833,
      "step": 11050
    },
    {
      "epoch": 4.44,
      "grad_norm": 0.7222328782081604,
      "learning_rate": 0.00055628,
      "loss": 0.161,
      "step": 11100
    },
    {
      "epoch": 4.46,
      "grad_norm": 3.6672799587249756,
      "learning_rate": 0.00055428,
      "loss": 0.209,
      "step": 11150
    },
    {
      "epoch": 4.48,
      "grad_norm": 0.11054592579603195,
      "learning_rate": 0.00055228,
      "loss": 0.1695,
      "step": 11200
    },
    {
      "epoch": 4.5,
      "grad_norm": 0.35984575748443604,
      "learning_rate": 0.00055028,
      "loss": 0.1732,
      "step": 11250
    },
    {
      "epoch": 4.52,
      "grad_norm": 3.661776542663574,
      "learning_rate": 0.00054828,
      "loss": 0.2191,
      "step": 11300
    },
    {
      "epoch": 4.54,
      "grad_norm": 1.266237735748291,
      "learning_rate": 0.00054628,
      "loss": 0.168,
      "step": 11350
    },
    {
      "epoch": 4.5600000000000005,
      "grad_norm": 4.692020893096924,
      "learning_rate": 0.00054428,
      "loss": 0.2009,
      "step": 11400
    },
    {
      "epoch": 4.58,
      "grad_norm": 4.980712890625,
      "learning_rate": 0.00054228,
      "loss": 0.2125,
      "step": 11450
    },
    {
      "epoch": 4.6,
      "grad_norm": 4.524273872375488,
      "learning_rate": 0.00054028,
      "loss": 0.1768,
      "step": 11500
    },
    {
      "epoch": 4.62,
      "grad_norm": 1.8433963060379028,
      "learning_rate": 0.00053828,
      "loss": 0.1941,
      "step": 11550
    },
    {
      "epoch": 4.64,
      "grad_norm": 2.198446750640869,
      "learning_rate": 0.00053628,
      "loss": 0.2019,
      "step": 11600
    },
    {
      "epoch": 4.66,
      "grad_norm": 2.0223805904388428,
      "learning_rate": 0.00053428,
      "loss": 0.2186,
      "step": 11650
    },
    {
      "epoch": 4.68,
      "grad_norm": 4.322869777679443,
      "learning_rate": 0.00053228,
      "loss": 0.198,
      "step": 11700
    },
    {
      "epoch": 4.7,
      "grad_norm": 2.9685044288635254,
      "learning_rate": 0.0005302799999999999,
      "loss": 0.2084,
      "step": 11750
    },
    {
      "epoch": 4.72,
      "grad_norm": 1.3063448667526245,
      "learning_rate": 0.00052828,
      "loss": 0.1886,
      "step": 11800
    },
    {
      "epoch": 4.74,
      "grad_norm": 4.8714985847473145,
      "learning_rate": 0.00052632,
      "loss": 0.2031,
      "step": 11850
    },
    {
      "epoch": 4.76,
      "grad_norm": 5.66290807723999,
      "learning_rate": 0.00052432,
      "loss": 0.2028,
      "step": 11900
    },
    {
      "epoch": 4.78,
      "grad_norm": 2.4958364963531494,
      "learning_rate": 0.00052232,
      "loss": 0.1592,
      "step": 11950
    },
    {
      "epoch": 4.8,
      "grad_norm": 4.178996562957764,
      "learning_rate": 0.00052032,
      "loss": 0.1829,
      "step": 12000
    },
    {
      "epoch": 4.82,
      "grad_norm": 5.830498695373535,
      "learning_rate": 0.0005183200000000001,
      "loss": 0.1801,
      "step": 12050
    },
    {
      "epoch": 4.84,
      "grad_norm": 1.417220950126648,
      "learning_rate": 0.0005163600000000001,
      "loss": 0.1891,
      "step": 12100
    },
    {
      "epoch": 4.86,
      "grad_norm": 2.877594470977783,
      "learning_rate": 0.0005143600000000001,
      "loss": 0.2037,
      "step": 12150
    },
    {
      "epoch": 4.88,
      "grad_norm": 5.554693698883057,
      "learning_rate": 0.00051236,
      "loss": 0.1714,
      "step": 12200
    },
    {
      "epoch": 4.9,
      "grad_norm": 2.8643054962158203,
      "learning_rate": 0.0005103600000000001,
      "loss": 0.206,
      "step": 12250
    },
    {
      "epoch": 4.92,
      "grad_norm": 1.1587748527526855,
      "learning_rate": 0.00050836,
      "loss": 0.1981,
      "step": 12300
    },
    {
      "epoch": 4.9399999999999995,
      "grad_norm": 3.5668227672576904,
      "learning_rate": 0.0005063600000000001,
      "loss": 0.198,
      "step": 12350
    },
    {
      "epoch": 4.96,
      "grad_norm": 7.782001972198486,
      "learning_rate": 0.00050436,
      "loss": 0.2194,
      "step": 12400
    },
    {
      "epoch": 4.98,
      "grad_norm": 2.7174413204193115,
      "learning_rate": 0.0005023600000000001,
      "loss": 0.2073,
      "step": 12450
    },
    {
      "epoch": 5.0,
      "grad_norm": 4.58496618270874,
      "learning_rate": 0.00050036,
      "loss": 0.1778,
      "step": 12500
    },
    {
      "epoch": 5.0,
      "eval_accuracy": 0.9217,
      "eval_f1": 0.9203377759690711,
      "eval_loss": 0.22701093554496765,
      "eval_runtime": 76.9511,
      "eval_samples_per_second": 129.953,
      "eval_steps_per_second": 4.068,
      "step": 12500
    },
    {
      "epoch": 5.02,
      "grad_norm": 1.9977409839630127,
      "learning_rate": 0.00049836,
      "loss": 0.1538,
      "step": 12550
    },
    {
      "epoch": 5.04,
      "grad_norm": 0.7125992774963379,
      "learning_rate": 0.00049636,
      "loss": 0.1597,
      "step": 12600
    },
    {
      "epoch": 5.06,
      "grad_norm": 2.5636751651763916,
      "learning_rate": 0.00049436,
      "loss": 0.1585,
      "step": 12650
    },
    {
      "epoch": 5.08,
      "grad_norm": 0.799615740776062,
      "learning_rate": 0.0004923600000000001,
      "loss": 0.1637,
      "step": 12700
    },
    {
      "epoch": 5.1,
      "grad_norm": 2.3079378604888916,
      "learning_rate": 0.00049036,
      "loss": 0.2083,
      "step": 12750
    },
    {
      "epoch": 5.12,
      "grad_norm": 2.2229886054992676,
      "learning_rate": 0.0004883600000000001,
      "loss": 0.1886,
      "step": 12800
    },
    {
      "epoch": 5.14,
      "grad_norm": 3.4521212577819824,
      "learning_rate": 0.00048636,
      "loss": 0.1523,
      "step": 12850
    },
    {
      "epoch": 5.16,
      "grad_norm": 4.600821495056152,
      "learning_rate": 0.00048436000000000003,
      "loss": 0.2044,
      "step": 12900
    },
    {
      "epoch": 5.18,
      "grad_norm": 5.853548526763916,
      "learning_rate": 0.00048236000000000004,
      "loss": 0.158,
      "step": 12950
    },
    {
      "epoch": 5.2,
      "grad_norm": 1.3673632144927979,
      "learning_rate": 0.00048036000000000004,
      "loss": 0.16,
      "step": 13000
    },
    {
      "epoch": 5.22,
      "grad_norm": 3.0555179119110107,
      "learning_rate": 0.00047836,
      "loss": 0.1684,
      "step": 13050
    },
    {
      "epoch": 5.24,
      "grad_norm": 0.656692385673523,
      "learning_rate": 0.00047636,
      "loss": 0.116,
      "step": 13100
    },
    {
      "epoch": 5.26,
      "grad_norm": 0.17667753994464874,
      "learning_rate": 0.00047436,
      "loss": 0.1538,
      "step": 13150
    },
    {
      "epoch": 5.28,
      "grad_norm": 0.5471676588058472,
      "learning_rate": 0.00047236,
      "loss": 0.1774,
      "step": 13200
    },
    {
      "epoch": 5.3,
      "grad_norm": 0.3121868968009949,
      "learning_rate": 0.00047036,
      "loss": 0.1652,
      "step": 13250
    },
    {
      "epoch": 5.32,
      "grad_norm": 2.4063820838928223,
      "learning_rate": 0.00046836,
      "loss": 0.162,
      "step": 13300
    },
    {
      "epoch": 5.34,
      "grad_norm": 2.8943731784820557,
      "learning_rate": 0.00046636000000000003,
      "loss": 0.1586,
      "step": 13350
    },
    {
      "epoch": 5.36,
      "grad_norm": 4.627204895019531,
      "learning_rate": 0.00046436,
      "loss": 0.2195,
      "step": 13400
    },
    {
      "epoch": 5.38,
      "grad_norm": 0.49825218319892883,
      "learning_rate": 0.00046236,
      "loss": 0.1533,
      "step": 13450
    },
    {
      "epoch": 5.4,
      "grad_norm": 3.7536284923553467,
      "learning_rate": 0.00046036,
      "loss": 0.1697,
      "step": 13500
    },
    {
      "epoch": 5.42,
      "grad_norm": 6.216217517852783,
      "learning_rate": 0.00045836,
      "loss": 0.183,
      "step": 13550
    },
    {
      "epoch": 5.44,
      "grad_norm": 4.714177131652832,
      "learning_rate": 0.00045636,
      "loss": 0.2043,
      "step": 13600
    },
    {
      "epoch": 5.46,
      "grad_norm": 0.606340765953064,
      "learning_rate": 0.00045436,
      "loss": 0.212,
      "step": 13650
    },
    {
      "epoch": 5.48,
      "grad_norm": 2.9766652584075928,
      "learning_rate": 0.00045236,
      "loss": 0.1681,
      "step": 13700
    },
    {
      "epoch": 5.5,
      "grad_norm": 1.07204270362854,
      "learning_rate": 0.00045036,
      "loss": 0.1506,
      "step": 13750
    },
    {
      "epoch": 5.52,
      "grad_norm": 5.359398365020752,
      "learning_rate": 0.00044835999999999997,
      "loss": 0.1602,
      "step": 13800
    },
    {
      "epoch": 5.54,
      "grad_norm": 0.2658271789550781,
      "learning_rate": 0.00044636,
      "loss": 0.1396,
      "step": 13850
    },
    {
      "epoch": 5.5600000000000005,
      "grad_norm": 7.207924842834473,
      "learning_rate": 0.00044436,
      "loss": 0.2108,
      "step": 13900
    },
    {
      "epoch": 5.58,
      "grad_norm": 0.21008358895778656,
      "learning_rate": 0.00044236,
      "loss": 0.1405,
      "step": 13950
    },
    {
      "epoch": 5.6,
      "grad_norm": 0.6899884939193726,
      "learning_rate": 0.00044036,
      "loss": 0.1662,
      "step": 14000
    },
    {
      "epoch": 5.62,
      "grad_norm": 0.48012223839759827,
      "learning_rate": 0.00043836000000000005,
      "loss": 0.1856,
      "step": 14050
    },
    {
      "epoch": 5.64,
      "grad_norm": 9.439105987548828,
      "learning_rate": 0.00043636000000000006,
      "loss": 0.212,
      "step": 14100
    },
    {
      "epoch": 5.66,
      "grad_norm": 0.38273200392723083,
      "learning_rate": 0.00043436,
      "loss": 0.1705,
      "step": 14150
    },
    {
      "epoch": 5.68,
      "grad_norm": 4.484753608703613,
      "learning_rate": 0.00043236,
      "loss": 0.1783,
      "step": 14200
    },
    {
      "epoch": 5.7,
      "grad_norm": 2.8516685962677,
      "learning_rate": 0.00043036,
      "loss": 0.1772,
      "step": 14250
    },
    {
      "epoch": 5.72,
      "grad_norm": 1.9583133459091187,
      "learning_rate": 0.00042836,
      "loss": 0.1604,
      "step": 14300
    },
    {
      "epoch": 5.74,
      "grad_norm": 1.8268201351165771,
      "learning_rate": 0.00042636000000000003,
      "loss": 0.1826,
      "step": 14350
    },
    {
      "epoch": 5.76,
      "grad_norm": 1.6398316621780396,
      "learning_rate": 0.00042436000000000004,
      "loss": 0.1515,
      "step": 14400
    },
    {
      "epoch": 5.78,
      "grad_norm": 8.692652702331543,
      "learning_rate": 0.00042236000000000004,
      "loss": 0.1678,
      "step": 14450
    },
    {
      "epoch": 5.8,
      "grad_norm": 3.8757529258728027,
      "learning_rate": 0.00042036,
      "loss": 0.1542,
      "step": 14500
    },
    {
      "epoch": 5.82,
      "grad_norm": 3.8802483081817627,
      "learning_rate": 0.00041836,
      "loss": 0.1333,
      "step": 14550
    },
    {
      "epoch": 5.84,
      "grad_norm": 6.738372325897217,
      "learning_rate": 0.00041636,
      "loss": 0.1885,
      "step": 14600
    },
    {
      "epoch": 5.86,
      "grad_norm": 3.6295101642608643,
      "learning_rate": 0.00041436,
      "loss": 0.1813,
      "step": 14650
    },
    {
      "epoch": 5.88,
      "grad_norm": 1.8249549865722656,
      "learning_rate": 0.00041236,
      "loss": 0.1965,
      "step": 14700
    },
    {
      "epoch": 5.9,
      "grad_norm": 0.6492307782173157,
      "learning_rate": 0.00041036,
      "loss": 0.1874,
      "step": 14750
    },
    {
      "epoch": 5.92,
      "grad_norm": 1.8083972930908203,
      "learning_rate": 0.00040836000000000003,
      "loss": 0.1536,
      "step": 14800
    },
    {
      "epoch": 5.9399999999999995,
      "grad_norm": 2.456526041030884,
      "learning_rate": 0.00040636000000000003,
      "loss": 0.165,
      "step": 14850
    },
    {
      "epoch": 5.96,
      "grad_norm": 6.348823070526123,
      "learning_rate": 0.00040436,
      "loss": 0.1575,
      "step": 14900
    },
    {
      "epoch": 5.98,
      "grad_norm": 4.772830009460449,
      "learning_rate": 0.00040236,
      "loss": 0.1637,
      "step": 14950
    },
    {
      "epoch": 6.0,
      "grad_norm": 3.5898597240448,
      "learning_rate": 0.00040036,
      "loss": 0.1726,
      "step": 15000
    },
    {
      "epoch": 6.0,
      "eval_accuracy": 0.9255,
      "eval_f1": 0.9247854618879354,
      "eval_loss": 0.22879445552825928,
      "eval_runtime": 76.9274,
      "eval_samples_per_second": 129.993,
      "eval_steps_per_second": 4.069,
      "step": 15000
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.9775089621543884,
      "learning_rate": 0.00039836,
      "loss": 0.1493,
      "step": 15050
    },
    {
      "epoch": 6.04,
      "grad_norm": 3.0720367431640625,
      "learning_rate": 0.00039636,
      "loss": 0.151,
      "step": 15100
    },
    {
      "epoch": 6.06,
      "grad_norm": 1.6748138666152954,
      "learning_rate": 0.00039436,
      "loss": 0.1492,
      "step": 15150
    },
    {
      "epoch": 6.08,
      "grad_norm": 4.791213512420654,
      "learning_rate": 0.00039240000000000005,
      "loss": 0.1369,
      "step": 15200
    },
    {
      "epoch": 6.1,
      "grad_norm": 7.983647346496582,
      "learning_rate": 0.00039040000000000006,
      "loss": 0.1425,
      "step": 15250
    },
    {
      "epoch": 6.12,
      "grad_norm": 6.512763977050781,
      "learning_rate": 0.0003884,
      "loss": 0.154,
      "step": 15300
    },
    {
      "epoch": 6.14,
      "grad_norm": 2.0847971439361572,
      "learning_rate": 0.0003864,
      "loss": 0.2036,
      "step": 15350
    },
    {
      "epoch": 6.16,
      "grad_norm": 2.578368902206421,
      "learning_rate": 0.0003844,
      "loss": 0.1355,
      "step": 15400
    },
    {
      "epoch": 6.18,
      "grad_norm": 5.980983257293701,
      "learning_rate": 0.0003824,
      "loss": 0.1399,
      "step": 15450
    },
    {
      "epoch": 6.2,
      "grad_norm": 1.642308235168457,
      "learning_rate": 0.00038040000000000003,
      "loss": 0.1554,
      "step": 15500
    },
    {
      "epoch": 6.22,
      "grad_norm": 0.6192494630813599,
      "learning_rate": 0.00037840000000000004,
      "loss": 0.1575,
      "step": 15550
    },
    {
      "epoch": 6.24,
      "grad_norm": 1.7288808822631836,
      "learning_rate": 0.00037640000000000004,
      "loss": 0.1354,
      "step": 15600
    },
    {
      "epoch": 6.26,
      "grad_norm": 5.910122871398926,
      "learning_rate": 0.0003744,
      "loss": 0.1434,
      "step": 15650
    },
    {
      "epoch": 6.28,
      "grad_norm": 1.2969460487365723,
      "learning_rate": 0.0003724,
      "loss": 0.1845,
      "step": 15700
    },
    {
      "epoch": 6.3,
      "grad_norm": 5.536355972290039,
      "learning_rate": 0.0003704,
      "loss": 0.1374,
      "step": 15750
    },
    {
      "epoch": 6.32,
      "grad_norm": 5.094545364379883,
      "learning_rate": 0.0003684,
      "loss": 0.184,
      "step": 15800
    },
    {
      "epoch": 6.34,
      "grad_norm": 3.5985896587371826,
      "learning_rate": 0.0003664,
      "loss": 0.1636,
      "step": 15850
    },
    {
      "epoch": 6.36,
      "grad_norm": 3.566892147064209,
      "learning_rate": 0.0003644,
      "loss": 0.1567,
      "step": 15900
    },
    {
      "epoch": 6.38,
      "grad_norm": 1.2748063802719116,
      "learning_rate": 0.0003624,
      "loss": 0.15,
      "step": 15950
    },
    {
      "epoch": 6.4,
      "grad_norm": 5.242627143859863,
      "learning_rate": 0.00036040000000000003,
      "loss": 0.1619,
      "step": 16000
    },
    {
      "epoch": 6.42,
      "grad_norm": 5.076951503753662,
      "learning_rate": 0.0003584,
      "loss": 0.1711,
      "step": 16050
    },
    {
      "epoch": 6.44,
      "grad_norm": 3.8303050994873047,
      "learning_rate": 0.0003564,
      "loss": 0.1551,
      "step": 16100
    },
    {
      "epoch": 6.46,
      "grad_norm": 5.2230000495910645,
      "learning_rate": 0.0003544,
      "loss": 0.1697,
      "step": 16150
    },
    {
      "epoch": 6.48,
      "grad_norm": 2.9215457439422607,
      "learning_rate": 0.0003524,
      "loss": 0.1326,
      "step": 16200
    },
    {
      "epoch": 6.5,
      "grad_norm": 1.9760302305221558,
      "learning_rate": 0.0003504,
      "loss": 0.1742,
      "step": 16250
    },
    {
      "epoch": 6.52,
      "grad_norm": 0.7778040170669556,
      "learning_rate": 0.0003484,
      "loss": 0.1452,
      "step": 16300
    },
    {
      "epoch": 6.54,
      "grad_norm": 3.747929334640503,
      "learning_rate": 0.0003464,
      "loss": 0.1314,
      "step": 16350
    },
    {
      "epoch": 6.5600000000000005,
      "grad_norm": 4.6985764503479,
      "learning_rate": 0.00034439999999999997,
      "loss": 0.1904,
      "step": 16400
    },
    {
      "epoch": 6.58,
      "grad_norm": 1.4297637939453125,
      "learning_rate": 0.0003424,
      "loss": 0.1689,
      "step": 16450
    },
    {
      "epoch": 6.6,
      "grad_norm": 0.5274027585983276,
      "learning_rate": 0.0003404,
      "loss": 0.1725,
      "step": 16500
    },
    {
      "epoch": 6.62,
      "grad_norm": 4.107967376708984,
      "learning_rate": 0.0003384,
      "loss": 0.1586,
      "step": 16550
    },
    {
      "epoch": 6.64,
      "grad_norm": 4.524362564086914,
      "learning_rate": 0.0003364,
      "loss": 0.1464,
      "step": 16600
    },
    {
      "epoch": 6.66,
      "grad_norm": 0.356444776058197,
      "learning_rate": 0.0003344,
      "loss": 0.1407,
      "step": 16650
    },
    {
      "epoch": 6.68,
      "grad_norm": 0.10855117440223694,
      "learning_rate": 0.0003324,
      "loss": 0.1468,
      "step": 16700
    },
    {
      "epoch": 6.7,
      "grad_norm": 3.1929335594177246,
      "learning_rate": 0.0003304,
      "loss": 0.1693,
      "step": 16750
    },
    {
      "epoch": 6.72,
      "grad_norm": 4.71739387512207,
      "learning_rate": 0.0003284,
      "loss": 0.1178,
      "step": 16800
    },
    {
      "epoch": 6.74,
      "grad_norm": 3.6876590251922607,
      "learning_rate": 0.0003264,
      "loss": 0.1593,
      "step": 16850
    },
    {
      "epoch": 6.76,
      "grad_norm": 0.8250059485435486,
      "learning_rate": 0.0003244,
      "loss": 0.1263,
      "step": 16900
    },
    {
      "epoch": 6.78,
      "grad_norm": 2.185525417327881,
      "learning_rate": 0.00032240000000000003,
      "loss": 0.1482,
      "step": 16950
    },
    {
      "epoch": 6.8,
      "grad_norm": 1.1003361940383911,
      "learning_rate": 0.00032040000000000004,
      "loss": 0.1524,
      "step": 17000
    },
    {
      "epoch": 6.82,
      "grad_norm": 7.024441719055176,
      "learning_rate": 0.00031840000000000004,
      "loss": 0.1512,
      "step": 17050
    },
    {
      "epoch": 6.84,
      "grad_norm": 5.9123215675354,
      "learning_rate": 0.00031640000000000005,
      "loss": 0.1703,
      "step": 17100
    },
    {
      "epoch": 6.86,
      "grad_norm": 3.999603271484375,
      "learning_rate": 0.0003144,
      "loss": 0.1637,
      "step": 17150
    },
    {
      "epoch": 6.88,
      "grad_norm": 0.2872868776321411,
      "learning_rate": 0.0003124,
      "loss": 0.1601,
      "step": 17200
    },
    {
      "epoch": 6.9,
      "grad_norm": 4.379833698272705,
      "learning_rate": 0.00031044,
      "loss": 0.1813,
      "step": 17250
    },
    {
      "epoch": 6.92,
      "grad_norm": 1.9020315408706665,
      "learning_rate": 0.00030844,
      "loss": 0.178,
      "step": 17300
    },
    {
      "epoch": 6.9399999999999995,
      "grad_norm": 4.275819301605225,
      "learning_rate": 0.00030644,
      "loss": 0.1674,
      "step": 17350
    },
    {
      "epoch": 6.96,
      "grad_norm": 3.993245840072632,
      "learning_rate": 0.00030444,
      "loss": 0.146,
      "step": 17400
    },
    {
      "epoch": 6.98,
      "grad_norm": 4.627720832824707,
      "learning_rate": 0.00030244,
      "loss": 0.1653,
      "step": 17450
    },
    {
      "epoch": 7.0,
      "grad_norm": 2.88917875289917,
      "learning_rate": 0.00030044,
      "loss": 0.1909,
      "step": 17500
    },
    {
      "epoch": 7.0,
      "eval_accuracy": 0.9295,
      "eval_f1": 0.9302601642101097,
      "eval_loss": 0.2007146179676056,
      "eval_runtime": 76.9302,
      "eval_samples_per_second": 129.988,
      "eval_steps_per_second": 4.069,
      "step": 17500
    },
    {
      "epoch": 7.02,
      "grad_norm": 2.8100497722625732,
      "learning_rate": 0.00029843999999999997,
      "loss": 0.1436,
      "step": 17550
    },
    {
      "epoch": 7.04,
      "grad_norm": 3.900578498840332,
      "learning_rate": 0.00029644,
      "loss": 0.1329,
      "step": 17600
    },
    {
      "epoch": 7.06,
      "grad_norm": 2.6173439025878906,
      "learning_rate": 0.00029444,
      "loss": 0.1599,
      "step": 17650
    },
    {
      "epoch": 7.08,
      "grad_norm": 0.18677079677581787,
      "learning_rate": 0.00029244,
      "loss": 0.1289,
      "step": 17700
    },
    {
      "epoch": 7.1,
      "grad_norm": 5.6643195152282715,
      "learning_rate": 0.00029044,
      "loss": 0.1392,
      "step": 17750
    },
    {
      "epoch": 7.12,
      "grad_norm": 3.0830540657043457,
      "learning_rate": 0.00028844,
      "loss": 0.12,
      "step": 17800
    },
    {
      "epoch": 7.14,
      "grad_norm": 1.3229373693466187,
      "learning_rate": 0.00028644,
      "loss": 0.1247,
      "step": 17850
    },
    {
      "epoch": 7.16,
      "grad_norm": 1.1137735843658447,
      "learning_rate": 0.00028444,
      "loss": 0.1066,
      "step": 17900
    },
    {
      "epoch": 7.18,
      "grad_norm": 3.603954315185547,
      "learning_rate": 0.00028244,
      "loss": 0.1632,
      "step": 17950
    },
    {
      "epoch": 7.2,
      "grad_norm": 6.454300403594971,
      "learning_rate": 0.00028044,
      "loss": 0.1619,
      "step": 18000
    },
    {
      "epoch": 7.22,
      "grad_norm": 2.1760761737823486,
      "learning_rate": 0.00027844,
      "loss": 0.1066,
      "step": 18050
    },
    {
      "epoch": 7.24,
      "grad_norm": 5.73081111907959,
      "learning_rate": 0.00027644000000000003,
      "loss": 0.114,
      "step": 18100
    },
    {
      "epoch": 7.26,
      "grad_norm": 5.876666069030762,
      "learning_rate": 0.00027444000000000004,
      "loss": 0.1712,
      "step": 18150
    },
    {
      "epoch": 7.28,
      "grad_norm": 1.2214149236679077,
      "learning_rate": 0.00027244000000000004,
      "loss": 0.1669,
      "step": 18200
    },
    {
      "epoch": 7.3,
      "grad_norm": 6.575469493865967,
      "learning_rate": 0.00027044,
      "loss": 0.1538,
      "step": 18250
    },
    {
      "epoch": 7.32,
      "grad_norm": 0.46984779834747314,
      "learning_rate": 0.00026844,
      "loss": 0.1524,
      "step": 18300
    },
    {
      "epoch": 7.34,
      "grad_norm": 0.1279711276292801,
      "learning_rate": 0.00026644,
      "loss": 0.1808,
      "step": 18350
    },
    {
      "epoch": 7.36,
      "grad_norm": 0.4827573001384735,
      "learning_rate": 0.00026444,
      "loss": 0.1096,
      "step": 18400
    },
    {
      "epoch": 7.38,
      "grad_norm": 1.723055362701416,
      "learning_rate": 0.00026244,
      "loss": 0.1344,
      "step": 18450
    },
    {
      "epoch": 7.4,
      "grad_norm": 0.146144300699234,
      "learning_rate": 0.00026044,
      "loss": 0.1943,
      "step": 18500
    },
    {
      "epoch": 7.42,
      "grad_norm": 3.900292158126831,
      "learning_rate": 0.00025844,
      "loss": 0.1445,
      "step": 18550
    },
    {
      "epoch": 7.44,
      "grad_norm": 0.030205469578504562,
      "learning_rate": 0.00025644000000000003,
      "loss": 0.1383,
      "step": 18600
    },
    {
      "epoch": 7.46,
      "grad_norm": 2.5563693046569824,
      "learning_rate": 0.00025444,
      "loss": 0.1323,
      "step": 18650
    },
    {
      "epoch": 7.48,
      "grad_norm": 7.040665626525879,
      "learning_rate": 0.00025244,
      "loss": 0.1417,
      "step": 18700
    },
    {
      "epoch": 7.5,
      "grad_norm": 2.034796953201294,
      "learning_rate": 0.00025044,
      "loss": 0.1442,
      "step": 18750
    },
    {
      "epoch": 7.52,
      "grad_norm": 0.08231788128614426,
      "learning_rate": 0.00024844,
      "loss": 0.1226,
      "step": 18800
    },
    {
      "epoch": 7.54,
      "grad_norm": 0.9116650223731995,
      "learning_rate": 0.00024644,
      "loss": 0.1557,
      "step": 18850
    },
    {
      "epoch": 7.5600000000000005,
      "grad_norm": 0.24937711656093597,
      "learning_rate": 0.00024444,
      "loss": 0.2055,
      "step": 18900
    },
    {
      "epoch": 7.58,
      "grad_norm": 0.5359420776367188,
      "learning_rate": 0.00024244,
      "loss": 0.1315,
      "step": 18950
    },
    {
      "epoch": 7.6,
      "grad_norm": 0.6105800867080688,
      "learning_rate": 0.00024044,
      "loss": 0.1277,
      "step": 19000
    },
    {
      "epoch": 7.62,
      "grad_norm": 2.1670000553131104,
      "learning_rate": 0.00023844000000000003,
      "loss": 0.1532,
      "step": 19050
    },
    {
      "epoch": 7.64,
      "grad_norm": 3.353085517883301,
      "learning_rate": 0.00023644,
      "loss": 0.1126,
      "step": 19100
    },
    {
      "epoch": 7.66,
      "grad_norm": 0.34369170665740967,
      "learning_rate": 0.00023444,
      "loss": 0.1599,
      "step": 19150
    },
    {
      "epoch": 7.68,
      "grad_norm": 1.335324764251709,
      "learning_rate": 0.00023244000000000002,
      "loss": 0.1601,
      "step": 19200
    },
    {
      "epoch": 7.7,
      "grad_norm": 4.693485736846924,
      "learning_rate": 0.00023044000000000002,
      "loss": 0.1838,
      "step": 19250
    },
    {
      "epoch": 7.72,
      "grad_norm": 3.6597421169281006,
      "learning_rate": 0.00022844,
      "loss": 0.1449,
      "step": 19300
    },
    {
      "epoch": 7.74,
      "grad_norm": 4.911680221557617,
      "learning_rate": 0.00022644,
      "loss": 0.1486,
      "step": 19350
    },
    {
      "epoch": 7.76,
      "grad_norm": 3.9900548458099365,
      "learning_rate": 0.00022444,
      "loss": 0.1512,
      "step": 19400
    },
    {
      "epoch": 7.78,
      "grad_norm": 0.8013898730278015,
      "learning_rate": 0.00022244,
      "loss": 0.1066,
      "step": 19450
    },
    {
      "epoch": 7.8,
      "grad_norm": 0.8157256841659546,
      "learning_rate": 0.00022044,
      "loss": 0.1126,
      "step": 19500
    },
    {
      "epoch": 7.82,
      "grad_norm": 3.924569606781006,
      "learning_rate": 0.00021844,
      "loss": 0.1615,
      "step": 19550
    },
    {
      "epoch": 7.84,
      "grad_norm": 5.86622953414917,
      "learning_rate": 0.00021644,
      "loss": 0.154,
      "step": 19600
    },
    {
      "epoch": 7.86,
      "grad_norm": 1.3671847581863403,
      "learning_rate": 0.00021444,
      "loss": 0.1728,
      "step": 19650
    },
    {
      "epoch": 7.88,
      "grad_norm": 5.662381172180176,
      "learning_rate": 0.00021244,
      "loss": 0.095,
      "step": 19700
    },
    {
      "epoch": 7.9,
      "grad_norm": 3.178337812423706,
      "learning_rate": 0.00021044,
      "loss": 0.1637,
      "step": 19750
    },
    {
      "epoch": 7.92,
      "grad_norm": 2.9777798652648926,
      "learning_rate": 0.00020844,
      "loss": 0.1567,
      "step": 19800
    },
    {
      "epoch": 7.9399999999999995,
      "grad_norm": 0.7811264991760254,
      "learning_rate": 0.00020644,
      "loss": 0.1296,
      "step": 19850
    },
    {
      "epoch": 7.96,
      "grad_norm": 3.2678956985473633,
      "learning_rate": 0.00020444000000000001,
      "loss": 0.1406,
      "step": 19900
    },
    {
      "epoch": 7.98,
      "grad_norm": 0.8082315325737,
      "learning_rate": 0.00020244000000000002,
      "loss": 0.1459,
      "step": 19950
    },
    {
      "epoch": 8.0,
      "grad_norm": 5.832468509674072,
      "learning_rate": 0.00020044,
      "loss": 0.1444,
      "step": 20000
    },
    {
      "epoch": 8.0,
      "eval_accuracy": 0.9283,
      "eval_f1": 0.928819616797379,
      "eval_loss": 0.23396535217761993,
      "eval_runtime": 76.9685,
      "eval_samples_per_second": 129.923,
      "eval_steps_per_second": 4.067,
      "step": 20000
    },
    {
      "epoch": 8.02,
      "grad_norm": 4.82255220413208,
      "learning_rate": 0.00019844,
      "loss": 0.1016,
      "step": 20050
    },
    {
      "epoch": 8.04,
      "grad_norm": 0.29423823952674866,
      "learning_rate": 0.00019644,
      "loss": 0.1336,
      "step": 20100
    },
    {
      "epoch": 8.06,
      "grad_norm": 1.1400690078735352,
      "learning_rate": 0.00019444000000000002,
      "loss": 0.0994,
      "step": 20150
    },
    {
      "epoch": 8.08,
      "grad_norm": 3.458127975463867,
      "learning_rate": 0.00019244,
      "loss": 0.1143,
      "step": 20200
    },
    {
      "epoch": 8.1,
      "grad_norm": 4.46554708480835,
      "learning_rate": 0.00019044,
      "loss": 0.1536,
      "step": 20250
    },
    {
      "epoch": 8.12,
      "grad_norm": 7.762374401092529,
      "learning_rate": 0.00018844,
      "loss": 0.0939,
      "step": 20300
    },
    {
      "epoch": 8.14,
      "grad_norm": 2.4205074310302734,
      "learning_rate": 0.00018644,
      "loss": 0.1347,
      "step": 20350
    },
    {
      "epoch": 8.16,
      "grad_norm": 0.10001615434885025,
      "learning_rate": 0.00018448,
      "loss": 0.0948,
      "step": 20400
    },
    {
      "epoch": 8.18,
      "grad_norm": 1.7720903158187866,
      "learning_rate": 0.00018248,
      "loss": 0.1273,
      "step": 20450
    },
    {
      "epoch": 8.2,
      "grad_norm": 0.21528980135917664,
      "learning_rate": 0.00018048,
      "loss": 0.1279,
      "step": 20500
    },
    {
      "epoch": 8.22,
      "grad_norm": 0.3817873001098633,
      "learning_rate": 0.00017848,
      "loss": 0.1601,
      "step": 20550
    },
    {
      "epoch": 8.24,
      "grad_norm": 3.9806647300720215,
      "learning_rate": 0.00017648,
      "loss": 0.1531,
      "step": 20600
    },
    {
      "epoch": 8.26,
      "grad_norm": 0.3935874104499817,
      "learning_rate": 0.00017448,
      "loss": 0.1241,
      "step": 20650
    },
    {
      "epoch": 8.28,
      "grad_norm": 0.6563262939453125,
      "learning_rate": 0.00017248,
      "loss": 0.1317,
      "step": 20700
    },
    {
      "epoch": 8.3,
      "grad_norm": 5.710618019104004,
      "learning_rate": 0.00017048,
      "loss": 0.1558,
      "step": 20750
    },
    {
      "epoch": 8.32,
      "grad_norm": 6.453765392303467,
      "learning_rate": 0.00016847999999999999,
      "loss": 0.1423,
      "step": 20800
    },
    {
      "epoch": 8.34,
      "grad_norm": 5.219919681549072,
      "learning_rate": 0.00016648,
      "loss": 0.1364,
      "step": 20850
    },
    {
      "epoch": 8.36,
      "grad_norm": 0.17545118927955627,
      "learning_rate": 0.00016448,
      "loss": 0.1039,
      "step": 20900
    },
    {
      "epoch": 8.38,
      "grad_norm": 1.6930105686187744,
      "learning_rate": 0.00016248000000000003,
      "loss": 0.1145,
      "step": 20950
    },
    {
      "epoch": 8.4,
      "grad_norm": 6.427061080932617,
      "learning_rate": 0.00016048,
      "loss": 0.1881,
      "step": 21000
    },
    {
      "epoch": 8.42,
      "grad_norm": 0.5969568490982056,
      "learning_rate": 0.00015848000000000001,
      "loss": 0.0879,
      "step": 21050
    },
    {
      "epoch": 8.44,
      "grad_norm": 5.269355297088623,
      "learning_rate": 0.00015648000000000002,
      "loss": 0.1279,
      "step": 21100
    },
    {
      "epoch": 8.46,
      "grad_norm": 2.240421772003174,
      "learning_rate": 0.00015448,
      "loss": 0.1306,
      "step": 21150
    },
    {
      "epoch": 8.48,
      "grad_norm": 0.26278477907180786,
      "learning_rate": 0.00015248,
      "loss": 0.1292,
      "step": 21200
    },
    {
      "epoch": 8.5,
      "grad_norm": 3.356328010559082,
      "learning_rate": 0.00015048,
      "loss": 0.137,
      "step": 21250
    },
    {
      "epoch": 8.52,
      "grad_norm": 5.967195510864258,
      "learning_rate": 0.00014848000000000001,
      "loss": 0.1497,
      "step": 21300
    },
    {
      "epoch": 8.54,
      "grad_norm": 0.26723307371139526,
      "learning_rate": 0.00014648,
      "loss": 0.1472,
      "step": 21350
    },
    {
      "epoch": 8.56,
      "grad_norm": 0.8857055306434631,
      "learning_rate": 0.00014448,
      "loss": 0.1147,
      "step": 21400
    },
    {
      "epoch": 8.58,
      "grad_norm": 1.8049983978271484,
      "learning_rate": 0.00014248,
      "loss": 0.1475,
      "step": 21450
    },
    {
      "epoch": 8.6,
      "grad_norm": 1.531734585762024,
      "learning_rate": 0.00014047999999999998,
      "loss": 0.1556,
      "step": 21500
    },
    {
      "epoch": 8.62,
      "grad_norm": 0.6003544330596924,
      "learning_rate": 0.00013848,
      "loss": 0.1013,
      "step": 21550
    },
    {
      "epoch": 8.64,
      "grad_norm": 3.635934829711914,
      "learning_rate": 0.00013648,
      "loss": 0.1307,
      "step": 21600
    },
    {
      "epoch": 8.66,
      "grad_norm": 6.40836763381958,
      "learning_rate": 0.00013448,
      "loss": 0.114,
      "step": 21650
    },
    {
      "epoch": 8.68,
      "grad_norm": 7.078271389007568,
      "learning_rate": 0.00013247999999999998,
      "loss": 0.1138,
      "step": 21700
    },
    {
      "epoch": 8.7,
      "grad_norm": 3.6570608615875244,
      "learning_rate": 0.00013048,
      "loss": 0.1486,
      "step": 21750
    },
    {
      "epoch": 8.72,
      "grad_norm": 6.1341657638549805,
      "learning_rate": 0.00012848000000000002,
      "loss": 0.1561,
      "step": 21800
    },
    {
      "epoch": 8.74,
      "grad_norm": 5.066307544708252,
      "learning_rate": 0.00012648000000000002,
      "loss": 0.1161,
      "step": 21850
    },
    {
      "epoch": 8.76,
      "grad_norm": 2.5690691471099854,
      "learning_rate": 0.00012448,
      "loss": 0.1311,
      "step": 21900
    },
    {
      "epoch": 8.78,
      "grad_norm": 0.18672463297843933,
      "learning_rate": 0.00012248,
      "loss": 0.1206,
      "step": 21950
    },
    {
      "epoch": 8.8,
      "grad_norm": 5.857831001281738,
      "learning_rate": 0.00012048000000000001,
      "loss": 0.1391,
      "step": 22000
    },
    {
      "epoch": 8.82,
      "grad_norm": 3.8815345764160156,
      "learning_rate": 0.00011848,
      "loss": 0.1504,
      "step": 22050
    },
    {
      "epoch": 8.84,
      "grad_norm": 3.565772533416748,
      "learning_rate": 0.00011648,
      "loss": 0.1427,
      "step": 22100
    },
    {
      "epoch": 8.86,
      "grad_norm": 4.802065849304199,
      "learning_rate": 0.00011448,
      "loss": 0.1038,
      "step": 22150
    },
    {
      "epoch": 8.88,
      "grad_norm": 1.2647582292556763,
      "learning_rate": 0.00011248,
      "loss": 0.1457,
      "step": 22200
    },
    {
      "epoch": 8.9,
      "grad_norm": 0.14755800366401672,
      "learning_rate": 0.00011048,
      "loss": 0.1218,
      "step": 22250
    },
    {
      "epoch": 8.92,
      "grad_norm": 7.5959978103637695,
      "learning_rate": 0.00010847999999999999,
      "loss": 0.1042,
      "step": 22300
    },
    {
      "epoch": 8.94,
      "grad_norm": 4.508498191833496,
      "learning_rate": 0.00010648000000000001,
      "loss": 0.1375,
      "step": 22350
    },
    {
      "epoch": 8.96,
      "grad_norm": 3.83713436126709,
      "learning_rate": 0.00010448,
      "loss": 0.145,
      "step": 22400
    },
    {
      "epoch": 8.98,
      "grad_norm": 0.22141480445861816,
      "learning_rate": 0.00010248000000000001,
      "loss": 0.1132,
      "step": 22450
    },
    {
      "epoch": 9.0,
      "grad_norm": 5.522074222564697,
      "learning_rate": 0.00010048,
      "loss": 0.1638,
      "step": 22500
    },
    {
      "epoch": 9.0,
      "eval_accuracy": 0.9305,
      "eval_f1": 0.9300312091009766,
      "eval_loss": 0.23112930357456207,
      "eval_runtime": 76.953,
      "eval_samples_per_second": 129.949,
      "eval_steps_per_second": 4.067,
      "step": 22500
    }
  ],
  "logging_steps": 50,
  "max_steps": 25000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 4.745214646069786e+16,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
